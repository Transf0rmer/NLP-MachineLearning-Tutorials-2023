{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2023-Tutorial-Notebooks/blob/main/tutorial_notebooks/06_similarity_analogy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e27f41",
      "metadata": {
        "id": "f4e27f41"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "455293d9",
      "metadata": {
        "id": "455293d9"
      },
      "outputs": [],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9bc39df",
      "metadata": {
        "origin_pos": 0,
        "id": "d9bc39df"
      },
      "source": [
        "# Word Similarity and Analogy\n",
        ":label:`sec_synonyms`\n",
        "\n",
        "In :numref:`sec_word2vec_pretraining`,\n",
        "we trained a word2vec model on a small dataset,\n",
        "and applied it\n",
        "to find semantically similar words\n",
        "for an input word.\n",
        "In practice,\n",
        "word vectors that are pretrained\n",
        "on large corpora can be\n",
        "applied to downstream\n",
        "natural language processing tasks,\n",
        "which will be covered later\n",
        "in :numref:`chap_nlp_app`.\n",
        "To demonstrate\n",
        "semantics of pretrained word vectors\n",
        "from large corpora in a straightforward way,\n",
        "let's apply them\n",
        "in the word similarity and analogy tasks.\n"
      ]
    },
    {
      "cell_type": "code",
  