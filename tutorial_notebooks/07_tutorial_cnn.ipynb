{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2023-Tutorial-Notebooks/blob/main/tutorial_notebooks/07_tutorial_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7Ic2n5f6Wve"
      },
      "outputs": [],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyrhwMu0BoJZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TITzFYHoOKeT"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data, torchvision as tv\n",
        "import lightning as L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNNEe9D1CvNW"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank('en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8I3RZErWOKeU",
        "outputId": "6cefa911-18f2-4967-9056-66a332990abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 7 GPU(s) available.\n",
            "Device name: NVIDIA GeForce GTX TITAN X\n"
          ]
        }
      ],
      "source": [
        "# use the GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY5WvZMPBuMZ"
      },
      "outputs": [],
      "source": [
        "# download the dataset with wget\n",
        "# if the dataset is on github, try git clone instead.\n",
        "!wget -P \"data/\" https://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
        "# unpack the file\n",
        "!tar xvzf 'data/rt-polaritydata.tar.gz' -C 'data/'\n",
        "!mv data/rt-polaritydata/rt-polarity.neg data/\n",
        "!mv data/rt-polaritydata/rt-polarity.pos data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZV7yzsYDk5D"
      },
      "outputs": [],
      "source": [
        "# import the dataset (txt file) line by line\n",
        "def load_text(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        texts = []\n",
        "        for line in f:\n",
        "            texts.append(line.decode(errors='ignore').lower().strip())\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxRgXT3vD2ix"
      },
      "outputs": [],
      "source": [
        "neg_text = load_text(\"movie_review_data/data/rt-polarity.neg\")\n",
        "pos_text = load_text(\"movie_review_data/data/rt-polarity.pos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI5fdo22UKqe"
      },
      "outputs": [],
      "source": [
        "# concat negative and positive texts\n",
        "texts = neg_text + pos_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64j9QLGHOKeW",
        "outputId": "bb57b346-392f-4657-daa2-ae0fbf114a44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['simplistic , silly and tedious .',\n",
              " \"it's so laddish and juvenile , only teenage boys could possibly find it funny .\",\n",
              " 'exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable .',\n",
              " '[garbus] discards the potential for pathological study , exhuming instead , the skewed melodrama of the circumstantial situation .',\n",
              " 'a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification .']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6tsNU7gUgoF"
      },
      "outputs": [],
      "source": [
        "# we know the order in texts variable, so we can label it accordingly\n",
        "labels = np.array([0]*len(neg_text) + [1]*len(pos_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqP3wWAbffH_"
      },
      "outputs": [],
      "source": [
        "def tokenize(texts):\n",
        "  \"\"\"\n",
        "  Assign unique id to each token\n",
        "  \"\"\"\n",
        "  max_len = 0