{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2023-Tutorial-Notebooks/blob/main/tutorial_notebooks/03_tutorial_pipeline_skorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gzHo80DX3J0"
      },
      "source": [
        "# Introduction to sklearn Pipeline and skorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVB8QC6bX3J5"
      },
      "source": [
        "In this tutorial, we will introduce\n",
        "* the Pipeline class of sklearn\n",
        "* the skorch library: a framework unifying pytorch and sklearn.\n",
        "\n",
        "Based on the notebook of Phillip Str√∂bel (adjustments from Janis Goldzycher, Andrianos Michail)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuLQDR5MX3J6"
      },
      "source": [
        "## Recap\n",
        "\n",
        "We are still working with the text classification data from http://qwone.com/~jason/20Newsgroups/.\n",
        "Cf. notebook from last week for more comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuV1TvUNX3J7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def create_df(path_to_data, random_state=42):\n",
        "    \"\"\"\n",
        "    Takes the path of a folder containing all the subfolders (which contain the actual documents).\n",
        "    Builds a pandas datafram with document ids, the text and the label.\n",
        "    :param path_to_data: path to top folder as a string\n",
        "    :param random_state: integer, seed for shuffling\n",
        "    :return: pandas dataframe with all th\n",
        "    \"\"\"\n",
        "    doc_list = list()  # doc_list now: [[doc<str>, label<str>], ...]\n",
        "\n",
        "    for category in os.listdir(path_to_data):\n",
        "        for document in os.listdir(os.path.join(path_to_data, category)):\n",
        "            doc = open(os.path.join(path_to_data, category, document), 'r', encoding='latin-1').read().replace('\\n', ' ')\n",
        "            doc_list.append([doc, category])\n",
        "\n",
        "    df = pd.DataFrame(doc_list, columns=['text', 'label'])\n",
        "\n",
        "    return df.sample(frac=1, random_state=random_state) # return and shuffle dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhNP5KxyX3J8"
      },
      "outputs": [],
      "source": [
        "train = create_df('../datasets/20news-bydate/20news-bydate-train')\n",
        "test = create_df('../datasets/20news-bydate/20news-bydate-test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuvWeXL2X3J8"
      },
 