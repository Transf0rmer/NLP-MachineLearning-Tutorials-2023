{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2023-Tutorial-Notebooks/blob/main/tutorial_notebooks/02_basic_text_preprocessing_template_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9587a044",
      "metadata": {
        "papermill": {
          "duration": 0.011663,
          "end_time": "2022-09-13T13:53:07.969504",
          "exception": false,
          "start_time": "2022-09-13T13:53:07.957841",
          "status": "completed"
        },
        "tags": [],
        "id": "9587a044"
      },
      "source": [
        "Text pre-processing is one of mandatory steps we will preform while creating a NLP application. As humans, the text we usually write contains lots of spelling errors, short words, special symbols, emojis, etc, which we can understand but we need to preprocess this text if we want the computer to understand it. In this notebook, we will discuss some of the types of text pre-processing you will need to perform while working with text data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27c8725d",
      "metadata": {
        "papermill": {
          "duration": 0.009371,
          "end_time": "2022-09-13T13:53:07.988783",
          "exception": false,
          "start_time": "2022-09-13T13:53:07.979412",
          "status": "completed"
        },
        "tags": [],
        "id": "27c8725d"
      },
      "source": [
        "## **Table of Contents**\n",
        "> 1. [Lowercasing](#1)\n",
        "> 2. [Removing HTML Tags](#2)\n",
        "> 3. [Removing URLs](#3)\n",
        "> 4. [Removing Punctuations](#4)\n",
        "> 5. [Chat word treatment](#5)\n",
        "> 6. [Spelling Correction](#6)\n",
        "> 7. [Removing stop words](#7)\n",
        "> 8. [Handling Emojis](#8)\n",
        "> 9. [Tokenization](#9)\n",
        ">10. [Stemming](#10)\n",
        ">11. [References](#11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fa31c53",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-13T13:53:08.010290Z",
          "iopub.status.busy": "2022-09-13T13:53:08.009670Z",
          "iopub.status.idle": "2022-09-13T13:53:09.948051Z",
          "shell.execute_reply": "2022-09-13T13:53:09.946853Z"
        },
        "papermill": {
          "duration": 1.952945,
          "end_time": "2022-09-13T13:53:09.951341",
          "exception": false,
          "start_time": "2022-09-13T13:53:07.998396",
          "status": "completed"
        },
        "tags": [],
        "id": "5fa31c53"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "imdb_reviews = pd.read_csv('../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
        "twitter_tweets = pd.read_csv('../input/twitter-sentiment-analysis-hatred-speech/train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b65df54",
      "metadata": {
        "papermill": {
          "duration": 0.009969,
          "end_time": "2022-09-13T13:53:09.970699",
          "exception": false,
          "start_time": "2022-09-13T13:53:09.960730",
          "