
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MZ6F8ZM1X3KJ",
        "vOpydQgDX3KK"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrian0s/ML4NLP1-2023-Tutorial-Notebooks/blob/main/tutorial_notebooks/02_intro_to_sklearn_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gzHo80DX3J0"
      },
      "source": [
        "# Introduction to scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVB8QC6bX3J5"
      },
      "source": [
        "We would like to introduce you to scikit-learn with the help of an instructional example about text classification. We will cover the most basic principles and ideas about scikit-learn in this notebook. This tutorial is inspired by the sklearn tutorial on http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html, but contains a few more explanations and is suited to introduce scikit-learn in class.\n",
        "\n",
        "$Author$: Phillip Str√∂bel\n",
        "\n",
        "With adjustments from: Janis Goldzycher, Andrianos Michail\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuLQDR5MX3J6"
      },
      "source": [
        "## Data\n",
        "\n",
        "Get the data from http://qwone.com/~jason/20Newsgroups/. We will work with the 20news-bydate.tar.gz data set. Unzip it to a suitable destination. Here, all the data lies in the data folder. To our convenience, it has already been split into a training and a test set, so we don't have to care about this. What we need to do though is get the data and put it into a dataframe (you could also only work with dictionaries or other data containers). We do this for both the training and the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuV1TvUNX3J7"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def create_df(path_to_data, random_state=42):\n",
        "    \"\"\"\n",
        "    Takes the path of a folder containing all the subfolders (which contain the actual documents).\n",
        "    Builds a pandas datafram with document ids, the text and the label.\n",
        "    :param path_to_data: path to top folder as a string\n",
        "    :param random_state: integer, seed for shuffling\n",
        "    :return: pandas dataframe with all th\n",
        "    \"\"\"\n",
        "    doc_list = list()  # doc_list now: [[doc<str>, label<str>], ...]\n",
        "\n",
        "    for category in os.listdir(path_to_data):\n",
        "        for document in os.listdir(os.path.join(path_to_data, category)):\n",
        "            doc = open(os.path.join(path_to_data, category, document), 'r', encoding='latin-1').read().replace('\\n', ' ')\n",
        "            doc_list.append([doc, category])\n",
        "\n",
        "    df = pd.DataFrame(doc_list, columns=['text', 'label'])\n",
        "\n",
        "    return df.sample(frac=1, random_state=random_state) # return and shuffle dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhNP5KxyX3J8"
      },
      "source": [
        "train = create_df('data/20news-bydate/20news-bydate-train')\n",
        "test = create_df('data/20news-bydate/20news-bydate-test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuvWeXL2X3J8"
      },
      "source": [
        "Several ways to inspect the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSiZBH2nX3J9",
        "outputId": "e4fe6645-3622-4bdf-ba4a-1ff8d60e7bab"
      },
      "source": [
        "print('training size: ', train.shape)\n",
        "print('test size: ', test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training size:  (11314, 2)\n",
            "test size:  (7532, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1hM5sIuX3J-",
        "outputId": "3a090399-6064-4240-8f70-a66e5727627a"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7492</th>\n",
              "      <td>From: prb@access.digex.com (Pat) Subject: Re: ...</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3546</th>\n",
              "      <td>From: jcj@tellabs.com (jcj) Subject: Re: Losin...</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5582</th>\n",
              "      <td>From: hacker@cco.caltech.edu (Jonathan Bruce H...</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4793</th>\n",
              "      <td>From: harmons@.WV.TEK.COM (Harmon Sommer) Subj...</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3813</th>\n",
              "      <td>From: dppeak@matt.ksu.ksu.edu (David Paul Peak...</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  \\\n",
              "7492  From: prb@access.digex.com (Pat) Subject: Re: ...   \n",
              "3546  From: jcj@tellabs.com (jcj) Subject: Re: Losin...   \n",
              "5582  From: hacker@cco.caltech.edu (Jonathan Bruce H...   \n",
              "4793  From: harmons@.WV.TEK.COM (Harmon Sommer) Subj...   \n",
              "3813  From: dppeak@matt.ksu.ksu.edu (David Paul Peak...   \n",
              "\n",
              "                       label  \n",
              "7492               sci.space  \n",
              "3546  soc.religion.christian  \n",
              "5582               rec.autos  \n",
              "4793         rec.motorcycles  \n",
              "3813   comp.sys.mac.hardware  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "63bHHHJEX3J_",
        "outputId": "80e73c38-b6af-4a33-ed3e-9a3602853233"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11314 entries, 7492 to 7270\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    11314 non-null  object\n",
            " 1   label   11314 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 265.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfXDPPx2X3KA",
        "outputId": "66bb7cdc-6c58-44c6-9df8-7cf518a661cb"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11314</td>\n",
              "      <td>11314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>11314</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>From: gt6511a@prism.gatech.EDU (COCHRANE,JAMES...</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text             label\n",
              "count                                               11314             11314\n",
              "unique                                              11314                20\n",
              "top     From: gt6511a@prism.gatech.EDU (COCHRANE,JAMES...  rec.sport.hockey\n",
              "freq                                                    1               600"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXZ8GGUIX3KA",
        "outputId": "e0a85072-125c-4b17-bccc-61c93bea3d8f"
      },
      "source": [
        "train.groupby('label').size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "alt.atheism                 480\n",
              "comp.graphics               584\n",
              "comp.os.ms-windows.misc     591\n",
              "comp.sys.ibm.pc.hardware    590\n",
              "comp.sys.mac.hardware       578\n",
              "comp.windows.x              593\n",
              "misc.forsale                585\n",
              "rec.autos                   594\n",
              "rec.motorcycles             598\n",
              "rec.sport.baseball          597\n",
              "rec.sport.hockey            600\n",
              "sci.crypt                   595\n",
              "sci.electronics             591\n",
              "sci.med                     594\n",
              "sci.space                   593\n",
              "soc.religion.christian      599\n",
              "talk.politics.guns          546\n",
              "talk.politics.mideast       564\n",
              "talk.politics.misc          465\n",
              "talk.religion.misc          377\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpIz2S4PX3KA"
      },
      "source": [
        "As usual, we split the labels from the training and the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r6WywPEX3KB"
      },
      "source": [
        "X_train = train.text\n",
        "y_train = train.label\n",
        "X_test = test.text\n",
        "y_test = test.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCaHvzBVX3KB",
        "outputId": "73199120-60b3-46d6-e9e8-924de4593f71"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmuRdUSSX3KC"
      },
      "source": [
        "Series is just a \"One-dimensional ndarray with axis labels\". Let's see if we got this right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3PoWkuRX3KC",
        "outputId": "8f5faec4-8ae5-4195-caa9-cc320f0e7962"
      },
      "source": [
        "print('Training set shape: ', X_train.shape)\n",
        "print('Training labels shape: ', y_train.shape)\n",
        "print('Test set shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape:  (11314,)\n",
            "Training labels shape:  (11314,)\n",
            "Test set shape:  (7532,)\n",
            "Test labels shape:  (7532,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJvHvu5pX3KD",
        "outputId": "9f6a125b-7d94-45e0-c823-5b82c941ec24"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7492    From: prb@access.digex.com (Pat) Subject: Re: ...\n",
              "3546    From: jcj@tellabs.com (jcj) Subject: Re: Losin...\n",
              "5582    From: hacker@cco.caltech.edu (Jonathan Bruce H...\n",
              "4793    From: harmons@.WV.TEK.COM (Harmon Sommer) Subj...\n",
              "3813    From: dppeak@matt.ksu.ksu.edu (David Paul Peak...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyUIWl1BX3KD"
      },
      "source": [
        "## Preprocessing\n",
        "So far, so good! But we know that machine learning algorithms cannot work with text data directly. So we need to vectorise the data somehow. also, we might do some preprocessing. Let's see how we can tackle these problems.\n",
        "### Vectorise the data\n",
        "Luckily, sklearn offers some nice classes which help us. We should tokenise the data and then vectorise it. Conveniently, sklearns `CountVectoriser()` does exactly that. Let's see how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_T0KafxX3KD"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)  # num_docs x num_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jINuDaIX3KD"
      },
      "source": [
        "Basically, the three central methods in sklearn are `transform`, `fit`, `fit_transform`, and `predict`. We will see how each of these work and when to use them. We have alredy made use of `fit_transform`. Instead of using this method, we could have called the method `fit` on the training set first and the use `transform` to vectorise the data (to 'transform' it). With the fitted `CountVectorizer` we can now transform other data, like for example the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Ma6B6DX3KE"
      },
      "source": [
        "X_test_counts = count_vect.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9P64uoyX3KE"
      },
      "source": [
        "We will return to this later. First let us see what `CountVectorizer` produces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1LDpV78X3KE",
        "outputId": "f74dae93-35ea-4f8b-b56e-3819d4f39c5f"
      },
      "source": [
        "X_train_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<11314x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1787565 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-d5NODYX3KF"
      },
      "source": [
        "The vectorised form contains 11314 rows, which is the number of our documents, while the number of columns tells us something about the vocabulary size of the whole corpus. But what's a sparse matrix? Note that saving the complete, sparse document-vocabulary matrix would need to hold 1,472,030,598 values, most of which would be zero? Why? Instead, we only save 1,787,565 values in a compressed sparse row format. An example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIUos_j5X3KF",
        "outputId": "f56ea9cb-0435-4c9f-ea32-0f7233679398"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "row = np.array([0, 0, 1, 2, 2, 2])\n",
        "col = np.array([0, 2, 2, 0, 1, 2])\n",
        "data = np.array([1, 2, 3, 4, 5, 6])\n",
        "mtx = sparse.csr_matrix((data, (row, col)), shape=(3, 3))\n",
        "mtx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<3x3 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 6 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMN2JG4AX3KF",
        "outputId": "f222d09c-bdcd-4f4e-a9fa-599dcb043d3f"
      },
      "source": [
        "m = mtx.todense()\n",
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[1, 0, 2],\n",
              "        [0, 0, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCUnpTCDX3KF",
        "outputId": "749ec602-a5c6-44ee-e6fc-fc235ac50e28"
      },
      "source": [
        "m[0,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZpgzsfKX3KF",
        "outputId": "316c84bf-23ca-4b24-af21-12dfdd89e79e"
      },
      "source": [
        "m[0,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "matrix([[1, 0, 2]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIBL28e0X3KG"
      },
      "source": [
        "How does indexing and printing of sparse matrices work?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ2BCNwrX3KG",
        "outputId": "883fe8d6-8e4a-4b06-d8b7-0740ef8f774d"
      },
      "source": [
        "print(mtx[:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 0)\t1\n",
            "  (2, 0)\t4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f68k9dGPX3KG"
      },
      "source": [
        "Now let's apply our new knowledge to our word-document matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6i53jI-X3KG",
        "outputId": "f108b47e-a84d-43d2-d1bf-f17bb2499fd6"
      },
      "source": [
        "X_train_counts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap-exvLvX3KG",
        "outputId": "ea56dc71-1ff4-4c7b-acd9-aa7b4a677fc9"
      },
      "source": [
        "X_train_counts[0,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<1x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 60 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn2DMP8HX3KH"
      },
      "source": [
        "We can see which positions of the document vector are occupied. A `1` means the word occurs once in the document, while any other number gives the exact count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVaZB53rX3KH",
        "outputId": "60396dfc-423a-405e-f4db-12211187cec2"
      },
      "source": [
        "print(X_train_counts[0,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 56979)\t1\n",
            "  (0, 95455)\t1\n",
            "  (0, 25605)\t3\n",
            "  (0, 47246)\t2\n",
            "  (0, 41105)\t1\n",
            "  (0, 92305)\t2\n",
            "  (0, 111322)\t1\n",
            "  (0, 99721)\t1\n",
            "  (0, 107159)\t1\n",
            "  (0, 91242)\t1\n",
            "  (0, 123292)\t1\n",
            "  (0, 35456)\t1\n",
            "  (0, 29987)\t1\n",
            "  (0, 90379)\t1\n",
            "  (0, 53521)\t1\n",
            "  (0, 89917)\t1\n",
            "  (0, 41316)\t1\n",
            "  (0, 119714)\t1\n",
            "  (0, 76032)\t1\n",
            "  (0, 2927)\t1\n",
            "  (0, 87620)\t1\n",
            "  (0, 95162)\t1\n",
            "  (0, 64095)\t1\n",
            "  (0, 86694)\t1\n",
            "  (0, 114808)\t1\n",
            "  :\t:\n",
            "  (0, 28601)\t1\n",
            "  (0, 59779)\t1\n",
            "  (0, 107705)\t1\n",
            "  (0, 27001)\t1\n",
            "  (0, 65798)\t2\n",
            "  (0, 68766)\t2\n",
            "  (0, 42876)\t1\n",
            "  (0, 113279)\t2\n",
            "  (0, 90252)\t1\n",
            "  (0, 18888)\t1\n",
            "  (0, 114520)\t1\n",
            "  (0, 28012)\t1\n",
            "  (0, 90282)\t1\n",
            "  (0, 128402)\t1\n",
            "  (0, 71079)\t1\n",
            "  (0, 86493)\t2\n",
            "  (0, 122107)\t1\n",
            "  (0, 113172)\t1\n",
            "  (0, 48546)\t1\n",
            "  (0, 73201)\t2\n",
            "  (0, 114646)\t1\n",
            "  (0, 66184)\t1\n",
            "  (0, 28615)\t1\n",
            "  (0, 56283)\t1\n",
            "  (0, 112031)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA0pHM24X3KH"
      },
      "source": [
        "The number of words in a document is also trivial to get."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFXjDffNX3KH",
        "outputId": "d2f2d616-73d3-4a02-dc14-18854cc4fbcd"
      },
      "source": [
        "X_train_counts[0,:].sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBm5u0qCX3KH"
      },
      "source": [
        "In a similar fashion, we can count how many times a certain word occurs in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnhzqdTLX3KH",
        "outputId": "d57eebd6-e09e-43ea-dbaf-3dfb24d4189a"
      },
      "source": [
        "X_train_counts[:,0].sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1534"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKwmL2JlX3KH"
      },
      "source": [
        "We can also learn more about the vocabulary, e.g., how many times a word occurs in the corpus. First, we need to find the index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XD2f5zPX3KI",
        "outputId": "498030b1-ee8b-44bc-cb64-88fecce85147"
      },
      "source": [
        "count_vect.vocabulary_.get('sin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "107529"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odmWGpRHX3KI"
      },
      "source": [
        "Now we have the index, we can count how many times the word \"sin\" occurs in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSdMHbO-X3KI",
        "outputId": "cdab85e0-38bd-478a-e96c-ff502cedf156"
      },
      "source": [
        "sin_index = count_vect.vocabulary_.get('sin')\n",
        "X_train_counts[:,sin_index].sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "284"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlSBsNpoX3KI"
      },
      "source": [
        "So far, so good. `CountVectorizer` lets you also define if you want to count bigrams, or other n-grams. Moreover, you can not only count words, but als characters. We suggest you try these out for yourself. In the following, we will continue with unigrams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BuVj8CmX3KI"
      },
      "source": [
        "Since we have numbers now instead of strings, we could start training models now. However, raw counts will not be very informative, since we also have to take the length of a dodument into account. Dividing each row by the total number of words will give us the term frequency for each document. That will be much better! Now we still might have higher values for words which occur often in many documents. typically, these words are less informative, so we need to downscale those weights. This will modify or counts so that we are left with what is called the \"term frequency-inverse document frequency\" measure, or tf-idf. The tf-idf measure is given by\n",
        "\\begin{equation}\n",
        "f_{t,d}\\cdot log \\frac{N}{n_t}\n",
        "\\end{equation}\n",
        "In sklearn, there is the `TfidfTransformer` which does exactly that for us :-)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJXMA0q_X3KI"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_tranformer = TfidfTransformer(smooth_idf=True).fit(X_train_counts)\n",
        "X_train_tfidf = tfidf_tranformer.transform(X_train_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7Y76iwGX3KI",
        "outputId": "536ee9fd-1305-4770-e52d-a2a6d639e6fd"
      },
      "source": [
        "X_train_tfidf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJqpPKhyX3KJ",
        "outputId": "e9afdec0-7107-4890-e8d0-cef96a45888d"
      },
      "source": [
        "X_train_tfidf[0,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<1x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 60 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6UByJxUX3KJ",
        "outputId": "e9265411-968e-41bc-9e86-ac6f428494ea"
      },
      "source": [
        "print(X_train_tfidf[0,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 128402)\t0.040784535077023294\n",
            "  (0, 123292)\t0.050047475590731784\n",
            "  (0, 122107)\t0.23608192298840142\n",
            "  (0, 119714)\t0.07875000724650627\n",
            "  (0, 118561)\t0.08954168153621775\n",
            "  (0, 114808)\t0.09573115745960263\n",
            "  (0, 114646)\t0.050777861981411015\n",
            "  (0, 114520)\t0.06830757439166886\n",
            "  (0, 114455)\t0.02820701338545796\n",
            "  (0, 114440)\t0.03549606475525584\n",
            "  (0, 113279)\t0.16387685991792555\n",
            "  (0, 113172)\t0.22131647570679347\n",
            "  (0, 112031)\t0.08351647703105329\n",
            "  (0, 111322)\t0.02638497269006967\n",
            "  (0, 111152)\t0.19361694762246492\n",
            "  (0, 107705)\t0.11802257739846389\n",
            "  (0, 107159)\t0.15195563761417366\n",
            "  (0, 99721)\t0.036210478864209125\n",
            "  (0, 97123)\t0.09222812737895975\n",
            "  (0, 95455)\t0.15737149958892138\n",
            "  (0, 95162)\t0.04747820199185726\n",
            "  (0, 92305)\t0.2695561571516042\n",
            "  (0, 91242)\t0.18880639832564547\n",
            "  (0, 90379)\t0.0274484609010517\n",
            "  (0, 90282)\t0.1911021911312422\n",
            "  :\t:\n",
            "  (0, 65798)\t0.08764480627432894\n",
            "  (0, 64095)\t0.048786024742777\n",
            "  (0, 59779)\t0.06825052577984377\n",
            "  (0, 56979)\t0.02638497269006967\n",
            "  (0, 56283)\t0.034656523636315974\n",
            "  (0, 53521)\t0.13145063115405406\n",
            "  (0, 51353)\t0.16598346456058113\n",
            "  (0, 48753)\t0.0874317217290563\n",
            "  (0, 48546)\t0.058499941753033254\n",
            "  (0, 47246)\t0.27461404870175704\n",
            "  (0, 42876)\t0.06820497553514267\n",
            "  (0, 41785)\t0.14568990905086554\n",
            "  (0, 41316)\t0.11537829875562776\n",
            "  (0, 41105)\t0.04905995756763878\n",
            "  (0, 37565)\t0.09453279568632154\n",
            "  (0, 35456)\t0.14656221899872923\n",
            "  (0, 30044)\t0.047602978449929216\n",
            "  (0, 29987)\t0.18992933258978528\n",
            "  (0, 28615)\t0.0707846649625905\n",
            "  (0, 28601)\t0.05295157472547976\n",
            "  (0, 28012)\t0.04971794322459706\n",
            "  (0, 27001)\t0.18992933258978528\n",
            "  (0, 25605)\t0.29219228699617206\n",
            "  (0, 18888)\t0.19639688195070834\n",
            "  (0, 2927)\t0.09661785479371196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JRtlsIlX3KJ"
      },
      "source": [
        "Again we apply the transformation to the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGEiD2tWX3KJ"
      },
      "source": [
        "X_test_tfidf = tfidf_tranformer.transform(X_test_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyveNTbUX3KJ"
      },
      "source": [
        "This should suffice as features to train a classifer (for the moment)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ6F8ZM1X3KJ"
      },
      "source": [
        "### Vectorise labels\n",
        "Next, we deal with the labels. Every document has exactly one label attached. We have 20 labels in total. This means we can basically assign a number to each label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhdcRdMOX3KJ"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yedDDaqeX3KK",
        "outputId": "b637d0bb-44b5-47c1-84bf-c11e6d6c476d"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7QJT1iMX3KK",
        "outputId": "872716d7-830a-4609-8d6b-5e6bd68fafd6"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314,)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0G3-3BOX3KK",
        "outputId": "d86bc789-a2eb-444e-fe27-0131f3f76228"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7532,)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7QgLsXNX3KK",
        "outputId": "a0d4648d-de74-4b52-fc92-6dc248a62570"
      },
      "source": [
        "label_encoder.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
              "       'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
              "       'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
              "       'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
              "       'sci.electronics', 'sci.med', 'sci.space',\n",
              "       'soc.religion.christian', 'talk.politics.guns',\n",
              "       'talk.politics.mideast', 'talk.politics.misc',\n",
              "       'talk.religion.misc'], dtype=object)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOpydQgDX3KK"
      },
      "source": [
        "## Finally, let's train models\n",
        "Now it's time to train models. Let's stick to the Multinomial Naive Bayes classifier for the moment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5E49BmvX3KL",
        "outputId": "3ba527fb-79a0-456b-e67b-a2cef082427c"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_clf = MultinomialNB()\n",
        "nb_clf.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY8jOFswX3KL"
      },
      "source": [
        "Let's see how well we do on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qSKvif7X3KL",
        "outputId": "d8303229-208d-4e00-ab69-e81988bc4b7f"
      },
      "source": [
        "nb_clf.predict(X_test_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([18,  8, 11, ...,  2,  7, 15])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veDcE5vrX3KL",
        "outputId": "84a3e57d-30ed-4bb4-8056-44cec0add9fa"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([18,  8, 12, ...,  2,  9, 13])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSrwY3o8X3KL"
      },
      "source": [
        "Computing the accuracy is simple:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCBBI7ACX3KM",
        "outputId": "390974e6-a076-4b36-fc97-661b5ce6ce1d"
      },
      "source": [
        "correct = 0\n",
        "\n",
        "for index, prediction in enumerate(nb_clf.predict(X_test_tfidf)):\n",
        "    if prediction == y_test[index]:\n",
        "        correct +=1\n",
        "\n",
        "print('Accuracy: ', correct/y_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7738980350504514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwKSxJ4xX3KM",
        "outputId": "85e61f81-d5ba-4755-9cc5-5cb24371cc89"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(nb_clf.predict(X_test_tfidf), y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcTQCrM_X3KM"
      },
      "source": [
        "Almost 80 percent, that is not too bad. What about a Support Vector Classifier?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI33TO6QX3KM",
        "outputId": "4ec23ca3-bc00-4f86-b6be-66d1917621c1"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "svc = LinearSVC()\n",
        "svc.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJEbYM4ZX3KM",
        "outputId": "55a9ff20-14e9-475b-8658-f8d112e8f451"
      },
      "source": [
        "correct = 0\n",
        "\n",
        "for index, prediction in enumerate(svc.predict(X_test_tfidf)):\n",
        "    if prediction == y_test[index]:\n",
        "        correct +=1\n",
        "\n",
        "print('Accuracy: ', correct/y_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8531598513011153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxGpuK1pX3KM"
      },
      "source": [
        "An increase of 8%, that's good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qckHMB-X3KM"
      },
      "source": [
        "However, in order to determine the performance of our models we need cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIVCpA-rX3KN"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(nb_clf, X_train_tfidf, y_train, scoring='accuracy', cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADvb5_dwX3KN",
        "outputId": "940342a9-193c-48a6-9ef9-107cc540e64b"
      },
      "source": [
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.84628975, 0.84363958, 0.85159011, 0.84805654, 0.8311229 ,\n",
              "       0.85587975, 0.85499558, 0.8443855 , 0.85411141, 0.85057471])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgM4c9W-X3KN"
      },
      "source": [
        "scores = cross_val_score(svc, X_train_tfidf, y_train, scoring='accuracy', cv=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WanFN3RLX3KN",
        "outputId": "d8dc2eec-52ba-40c5-b35b-7c4c2f2addf0"
      },
      "source": [
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.92226148, 0.93639576, 0.93462898, 0.92932862, 0.9239611 ,\n",
              "       0.93015031, 0.92749779, 0.92307692, 0.93103448, 0.93280283])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1_rQidWX3KN"
      },
      "source": [
        "We can also calculate precision, recall, and f1 relatively easily:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H04oOtkMX3KN"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(max_iter=50)\n",
        "sgd_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_train_predictions = cross_val_predict(sgd_clf, X_train_tfidf, y_train, cv=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUrvEIDKX3KN",
        "outputId": "e13acd88-530b-46bc-b08d-e18d5aeb85a0"
      },
      "source": [
        "print(precision_score(y_train, y_train_predictions, average='micro'))\n",
        "print(recall_score(y_train, y_train_predictions, average='micro'))\n",
        "print(f1_score(y_train, y_train_predictions, average='micro'))\n",
        "conf_mx = confusion_matrix(y_train, y_train_predictions)\n",
        "conf_mx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9180661127806258\n",
            "0.9180661127806258\n",
            "0.9180661127806258\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[443,   1,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
              "          1,   1,   9,   1,   3,   0,  18],\n",
              "       [  0, 503,  23,  15,   5,  20,   6,   1,   0,   0,   1,   0,   3,\n",
              "          3,   4,   0,   0,   0,   0,   0],\n",
              "       [  1,  19, 524,  19,   3,  14,   5,   0,   0,   0,   0,   0,   3,\n",
              "          0,   1,   1,   0,   0,   1,   0],\n",
              "       [  0,  22,  32, 472,  15,   4,  17,   3,   0,   0,   2,   0,  23,\n",
              "          0,   0,   0,   0,   0,   0,   0],\n",
              "       [  1,   7,   7,  20, 513,   3,  10,   0,   4,   0,   0,   1,   7,\n",
              "          2,   1,   1,   0,   0,   1,   0],\n",
              "       [  0,  22,  10,   6,   1, 542,   2,   1,   1,   1,   2,   2,   1,\n",
              "          2,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   2,   3,  15,   4,   1, 518,  13,   5,   0,   5,   2,  11,\n",
              "          1,   1,   2,   0,   1,   1,   0],\n",
              "       [  0,   3,   3,   3,   2,   3,  10, 539,   9,   4,   1,   0,  10,\n",
              "          1,   1,   1,   2,   0,   2,   0],\n",
              "       [  1,   1,   0,   0,   2,   1,  12,   7, 571,   1,   0,   0,   1,\n",
              "          0,   1,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   1,   1,   0,   2,   2,   5,   2, 575,   6,   1,   1,\n",
              "          0,   0,   0,   0,   0,   1,   0],\n",
              "       [  0,   2,   0,   1,   1,   0,   3,   1,   0,   5, 584,   0,   0,\n",
              "          0,   0,   1,   0,   1,   1,   0],\n",
              "       [  1,   5,   1,   1,   0,   2,   0,   0,   0,   1,   2, 569,   4,\n",
              "          1,   0,   2,   1,   1,   4,   0],\n",
              "       [  0,   9,   4,  20,   6,   3,  11,   7,   2,   2,   2,   1, 517,\n",
              "          1,   3,   2,   0,   1,   0,   0],\n",
              "       [  0,   3,   2,   2,   2,   3,   3,   2,   0,   0,   0,   2,   5,\n",
              "        566,   2,   1,   1,   0,   0,   0],\n",
              "       [  0,   5,   0,   1,   1,   0,   3,   0,   0,   0,   0,   0,   1,\n",
              "          1, 577,   0,   1,   1,   2,   0],\n",
              "       [  4,   1,   3,   3,   1,   0,   2,   1,   0,   1,   1,   1,   1,\n",
              "          2,   0, 570,   1,   3,   0,   4],\n",
              "       [  0,   0,   1,   0,   0,   1,   3,   3,   1,   1,   1,   2,   0,\n",
              "          2,   1,   3, 524,   0,   2,   1],\n",
              "       [  1,   0,   0,   0,   0,   0,   1,   1,   0,   1,   0,   0,   0,\n",
              "          1,   0,   3,   0, 555,   1,   0],\n",